# DQN-
아주 간단한 gridworld를 만들어서 DQN을 연습해보겠습니다

좌우로만 이동할 수 있는 간단한 그리드월드입니다

[2, 0, -1, -2 ,10] 이렇게 보상이 주어진 상태이며

1번 자리에서 시작합니다.(보상이 0인 곳)

벽에 부딪히면 제자리에 머물며 -2점, 정상적으로 이동할때는 -1점입니다

우리는 제일 오른쪽(4번)으로 이동해야 최적인 것을 알고있습니다.

q-learning과 간단한 Q-Network로 어떻게 최적의 정책이 되는지 실행하면 출력 됩니다.

이 모델은 신경망이 5 X 16 X 16 X 2로 구성되어있으며 각 노드는 ReLU를 거칩니다

Input : State개수

Output : Action개수

보상을 10이 아닌 더 높게 설정하면 반복 수가 적어도 훨씬 빠르게 가지만 

모델이 직접 계산하여 10까지 갈 수 있길 바랬기에 일부러 적은 보상과 가는 길에 큰 위험을 두었습니다.

state의 수가 적기 때문에 batch size는 16으로 설정했으며 위험을 뚫고 큰 보상을 받기 위해 epsilon은 0.1이 아닌 0.2로 설정하였습니다

